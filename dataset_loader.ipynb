{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import islice, chain\n",
    "\n",
    "from torch.multiprocessing import Pool, SimpleQueue, JoinableQueue\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataLoader(object):\n",
    "    def __init__(self, df, transform,\n",
    "                 train_queue=SimpleQueue(), test_queue=SimpleQueue(),\n",
    "                 train_size=0.8, test_size=0.2, batch_size=10):\n",
    "        assert (train_size + test_size) == 1, 'Train test size should be fractions that sum to 1'\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.transform=transform\n",
    "        self.train_queue = train_queue\n",
    "        self.test_queue = test_queue\n",
    "        self.batch_size = batch_size\n",
    "        self.df = self.shuffle(df)\n",
    "        self.length = df.shape[0]\n",
    "        self.train_df, self.test_df = self.compute_train_test_df()\n",
    "\n",
    "    def shuffle(self, df):\n",
    "        return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def compute_train_test_df(self):\n",
    "        train_size = int(self.length * self.train_size)\n",
    "        test_size = int(self.length * self.test_size)\n",
    "        diff = self.length - sum([train_size, test_size])\n",
    "        return self.df.iloc[:train_size, :], self.df.iloc[train_size:, :]\n",
    "\n",
    "    def build_batches(self, df):\n",
    "        current_row = 0\n",
    "        num_batches = math.ceil(df.shape[0] / float(self.batch_size))\n",
    "        for _ in range(num_batches):\n",
    "            batch_X = []\n",
    "            batch_Y = []\n",
    "            for _, record in df.iloc[current_row:current_row + self.batch_size, :].iterrows():\n",
    "                batch = self.transform(record)\n",
    "                batch_X.append(batch[0])\n",
    "                batch_Y.append(batch[1])\n",
    "            current_row += self.batch_size\n",
    "            yield batch_X, batch_Y\n",
    "\n",
    "    def __iter__(self):\n",
    "        print(\"Train\")\n",
    "        idx = 0\n",
    "        for training_X, training_Y in self.build_batches(self.train_df):\n",
    "            self.train_queue.put((torch.tensor(training_X), torch.tensor(training_Y)))\n",
    "            idx += 1\n",
    "            yield idx\n",
    "        print(\"Test\")\n",
    "        idx = 0\n",
    "        for testing_X, testing_Y in self.build_batches(self.test_df):\n",
    "            self.test_queue.put((torch.tensor(testing_X), torch.tensor(testing_Y)))\n",
    "            idx += 1\n",
    "            yield idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('datasets/user_grouped_anime_ratings.gz').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "mapping = pickle.load(open('datasets/user_anime_ratings_mapping.pkl', 'rb'))\n",
    "mapping.keys()\n",
    "\n",
    "anime_embeddings = pickle.load(open('anime_embed_pytorch_nn_epoch4_embedding_fix_10.23-10.21.pkl', 'rb'))\n",
    "anime_embeddings.shape\n",
    "\n",
    "user_embeddings = pickle.load(open('user_embed_pytorch_nn_epoch4_embedding_fix_10.23-10.21.pkl', 'rb'))\n",
    "user_embeddings.shape\n",
    "\n",
    "from sklearn.decomposition.pca import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(user_embeddings.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def input_anime_embeddings(record, mapping, anime_embeddings):\n",
    "    num_records = len(record['anime_id'])\n",
    "    batch_anime_idx = np.array([mapping['anime2idx'][x] for x in record['anime_id']], dtype=np.int32)\n",
    "    batch_anime_rating = np.array(record['my_score'], dtype=np.int16)\n",
    "    num_anime_watched = len(batch_anime_idx)\n",
    "    sum_rating = np.sum(batch_anime_rating)\n",
    "    sum_rating = 1 if sum_rating == 0 else sum_rating\n",
    "    sum_neg_rating = np.sum(10 - batch_anime_rating)\n",
    "    sum_neg_rating = 1 if sum_neg_rating == 0 else sum_neg_rating\n",
    "    anime_sum = np.sum(\n",
    "        anime_embeddings[batch_anime_idx] * batch_anime_rating.reshape(-1, 1), axis=0\n",
    "    ).astype(np.float32)\n",
    "    anime_neg_sum = np.sum(\n",
    "        anime_embeddings[batch_anime_idx] * (10 - batch_anime_rating.reshape(-1, 1)), axis=0\n",
    "    ).astype(np.float32)\n",
    "    result_sum_rating =  anime_sum / sum_rating\n",
    "    result_mean_rating = anime_sum / num_anime_watched\n",
    "    result_sum_neg_rating = anime_neg_sum / sum_neg_rating\n",
    "    result = np.concatenate([\n",
    "        result_sum_rating,\n",
    "        result_sum_neg_rating,\n",
    "        result_mean_rating\n",
    "    ])\n",
    "    return result\n",
    "\n",
    "def extract_required_format(record, pca, mapping, user_embeddings, anime_embeddings, device):\n",
    "    return input_anime_embeddings(record, mapping, anime_embeddings), pca.transform([\n",
    "            user_embeddings[mapping['user2idx'][record['user_id']]]\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "transform = partial(extract_required_format, pca=pca, mapping=mapping,\n",
    "                    user_embeddings=user_embeddings.cpu().detach().numpy(),\n",
    "                    anime_embeddings=anime_embeddings.cpu().detach().numpy(), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderPool(object):\n",
    "    def __init__(self, data_loader, num_workers=4):\n",
    "        self.num_workers = num_workers\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def action(x):\n",
    "        return x\n",
    "\n",
    "    def run(self, chunksize=5):\n",
    "        def chunks(iterable, size=10):\n",
    "            iterator = iter(iterable)\n",
    "            for first in iterator:\n",
    "                yield chain([first], islice(iterator, size - 1))\n",
    "\n",
    "        with Pool(processes=self.num_workers) as pool:\n",
    "            for chunk in chunks(self.data_loader, size=chunksize):\n",
    "                for _ in pool.imap_unordered(DataLoaderPool.action, chunk):\n",
    "                    pass\n",
    "                yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlp = DataLoaderPool(\n",
    "    data_loader=PandasDataLoader(df=df.head(100), transform=transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = dlp.run(chunksize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Test\n"
     ]
    }
   ],
   "source": [
    "for _ in i:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlp.data_loader.train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    if dlp.data_loader.train_queue.empty() == False:\n",
    "        _ = dlp.data_loader.train_queue.get()\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
